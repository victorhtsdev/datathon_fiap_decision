{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8451ce7-275b-4374-94c7-9f087521f0d6",
   "metadata": {},
   "source": [
    "## Importa√ß√£o e configura√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2329e847-0cbc-4490-a5ae-1e32c514524b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "import subprocess\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# üîß Conex√£o com o banco\n",
    "DATABASE_URL = \"postgresql://postgres:super#@localhost:5433/decision_db\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "OLLAMA_MODEL = \"gemma3:4b-it-qat\"\n",
    "\n",
    "ordem_niveis = {\n",
    "    \"ensino m√©dio\": 1, \"t√©cnico\": 2, \"tecn√≥logo\": 4, \"especializa√ß√£o\": 3, \"gradua√ß√£o\": 5,\n",
    "    \"bacharel\": 6,\"p√≥s-gradua√ß√£o\": 7, \"MBA\": 8, \"mestrado\": 9, \"doutorado\": 10, \"certificacao\": 0\n",
    "}\n",
    "\n",
    "VALID_NIVEIS_IDIOMA = {\"b√°sico\", \"intermedi√°rio\", \"avan√ßado\", \"fluente\", \"nativo\"}\n",
    "\n",
    "CHUNK_SIZE = 5000 #Divide o arquivo do CV para n√£o sobrecarregar o modelo\n",
    "DEBUG = False\n",
    "SAVE_LOGS = False \n",
    "MAX_RETRIES = 10 # M√°ximo de tentativas para objter JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c40d559-a95a-4a1e-a3ad-d8264b09a557",
   "metadata": {},
   "source": [
    "## Fun√ß√µes gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa4e3722-bcad-43d9-b957-5e2b63088fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√µes Utilit√°rias\n",
    "def remove_ansi(text):\n",
    "    ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n",
    "    return ansi_escape.sub('', text)\n",
    "\n",
    "def corrigir_espacamento_letras(texto):\n",
    "    def corrigir_linha(linha):\n",
    "        return re.sub(r'((?:[A-Za-z√Ä-√ø]\\s){3,}[A-Za-z√Ä-√ø])', lambda m: m.group(0).replace(' ', ''), linha)\n",
    "    return '\\n'.join(corrigir_linha(l) for l in texto.splitlines())\n",
    "\n",
    "def split_chunks(text, size=CHUNK_SIZE):\n",
    "    chunks = [text[i:i+size] for i in range(0, len(text), size)]\n",
    "    if DEBUG:\n",
    "        print(f\"üîπ Total de chunks gerados: {len(chunks)}\")\n",
    "    return chunks\n",
    "\n",
    "def salvar_logs(nome_base, conteudo):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"logs/{nome_base}_{timestamp}.txt\"\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(conteudo)\n",
    "\n",
    "def remover_duplicatas(lista, chaves):\n",
    "    vistos = set()\n",
    "    unicos = []\n",
    "    for item in lista:\n",
    "        chave = tuple(str(item.get(k) or \"\").strip().lower() for k in chaves)\n",
    "        if chave not in vistos:\n",
    "            vistos.add(chave)\n",
    "            unicos.append(item)\n",
    "    return unicos\n",
    "\n",
    "def idioma_foi_mencionado(cv_text, idioma):\n",
    "    if not idioma:\n",
    "        return False\n",
    "    return re.search(rf\"\\b{re.escape(str(idioma))}\\b\", cv_text, re.IGNORECASE)\n",
    "\n",
    "def merge_results(r_form, r_exp, r_hab, r_idi):\n",
    "    return {\n",
    "        \"formacoes\": r_form.get(\"formacoes\", []),\n",
    "        \"experiencias\": r_exp.get(\"experiencias\", []),\n",
    "        \"habilidades\": r_hab.get(\"habilidades\", []),\n",
    "        \"idiomas\": r_idi.get(\"idiomas\", [])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a0f065-2803-4605-bfb0-a8d8a3f60b7f",
   "metadata": {},
   "source": [
    "## Busca registros n√£o processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f26aa06-782e-4ace-8816-2861419c4c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT a.id, a.informacoes_pessoais_data_aceite, a.informacoes_pessoais_nome,\n",
    "       a.informacoes_pessoais_cpf, a.informacoes_pessoais_fonte_indicacao,\n",
    "       a.informacoes_pessoais_email, a.informacoes_pessoais_email_secundario,\n",
    "       a.informacoes_pessoais_data_nascimento, a.informacoes_pessoais_telefone_celular,\n",
    "       a.informacoes_pessoais_telefone_recado, a.informacoes_pessoais_sexo,\n",
    "       a.informacoes_pessoais_estado_civil, a.informacoes_pessoais_pcd,\n",
    "       a.informacoes_pessoais_endereco, a.informacoes_pessoais_skype,\n",
    "       a.informacoes_pessoais_url_linkedin, a.informacoes_pessoais_facebook,\n",
    "       a.informacoes_pessoais_download_cv, a.cv_pt\n",
    "FROM applicants a\n",
    "LEFT JOIN processed_applicants p ON a.id = p.id\n",
    "WHERE p.id IS NULL\n",
    "LIMIT 10000\n",
    "\"\"\"\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    results = conn.execute(text(sql)).mappings().all()\n",
    "\n",
    "if not results:\n",
    "    print(\"Nenhum registro novo encontrado.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20d6330-7345-4bac-85c7-fe2912d6c4be",
   "metadata": {},
   "source": [
    "## Fun√ß√£o de extra√ß√£o e normaliza√ß√£o de CV com LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b82cb47e-0d2b-4250-a932-e5958f245ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_section(applicant_id, section_name, schema_snippet, cv_text):\n",
    "    cv_text = corrigir_espacamento_letras(cv_text)\n",
    "\n",
    "    if section_name == \"formacoes\":\n",
    "        prompt_base = (\n",
    "            f\"Voc√™ √© um especialista em RH. Extraia apenas a **forma√ß√£o acad√™mica formal** do curr√≠culo abaixo.\\n\\n\"\n",
    "            f\"‚ö†Ô∏è N√ÉO inclua experi√™ncias profissionais, cargos ou atividades realizadas no trabalho.\\n\"\n",
    "            f\"‚ö†Ô∏è N√ÉO confunda certifica√ß√µes, treinamentos curtos ou cursos livres com forma√ß√£o acad√™mica.\\n\"\n",
    "            f\"‚ö†Ô∏è Ignore nomes de empresas, fun√ß√µes (ex: analista, gerente, t√©cnico) e ambientes de trabalho.\\n\"\n",
    "            f\"‚ùå Nunca use nomes de empresas como institui√ß√£o de ensino.\\n\"\n",
    "            f\"‚ùå Nunca crie forma√ß√µes gen√©ricas sem curso expl√≠cito.\\n\"\n",
    "            f\"‚ùå Nunca invente cursos com base no nome de institui√ß√µes mencionadas em experi√™ncias profissionais (ex: onde a pessoa deu aula, participou de eventos ou prestou servi√ßos).\\n\"\n",
    "            f\"‚úÖ Considere apenas institui√ß√µes formais (escolas, faculdades, universidades, centros t√©cnicos reconhecidos).\\n\"\n",
    "            f\"‚úÖ Sempre inclua o ensino m√©dio (ex: 'ensino m√©dio', '2¬∫ grau completo') se for mencionado.\\n\\n\"\n",
    "            f\"üìå Certifica√ß√µes (ex: PMP, Java Programmer, SAFe Agilist) devem ser classificadas como tipo 'certificacao' no campo 'nivel'.\\n\"\n",
    "            f\"üìå Cursos livres, treinamentos, bootcamps, workshops e forma√ß√µes SAP devem ser classificados como tipo 'curso' no campo 'nivel'.\\n\"\n",
    "            f\"üìå Um curso simples ou certifica√ß√£o geralmente √© de curta dura√ß√£o, n√£o conduz a um diploma acad√™mico e √© focado em uma habilidade espec√≠fica.\\n\"\n",
    "            f\"üìå Nunca classifique certifica√ß√µes, cursos livres ou forma√ß√µes SAP como 'tecn√≥logo'.\\n\"\n",
    "            f\"üìå Cursos com nome iniciado por **'Tecnologia em ...'** devem ser classificados como **'tecn√≥logo'** (n√≠vel superior).\\n\"\n",
    "            f\"üìå Cursos com nome iniciado por **'T√©cnico em ...'** devem ser classificados como **'t√©cnico'** (n√≠vel m√©dio).\\n\"\n",
    "            f\"üìå Aten√ß√£o: **'Tecnologia'** no nome do curso indica um curso tecn√≥logo (superior), enquanto **'T√©cnico'** indica um curso t√©cnico (m√©dio). Nunca confunda os dois.\\n\\n\"\n",
    "            f\"Formato esperado (JSON com a chave '{section_name}'):\\n{schema_snippet}\\n\\n\"\n",
    "            f\"Regras obrigat√≥rias:\\n\"\n",
    "            f\"- Campo 'nivel': use apenas uma das op√ß√µes: ensino m√©dio, t√©cnico, tecn√≥logo, gradua√ß√£o, p√≥s-gradua√ß√£o, especializa√ß√£o, MBA, mestrado, doutorado, curso, certificacao.\\n\"\n",
    "            f\"- Campo 'observacoes': use apenas quando a forma√ß√£o estiver incompleta, trancada ou interrompida (ex: 'incompleto', 'trancado'); caso contr√°rio, use null.\\n\"\n",
    "            f\"- Os campos 'ano_inicio' e 'ano_fim' devem obrigatoriamente conter m√™s e ano no formato MM/YYYY. Exemplo v√°lido: '03/2018'.\\n\"\n",
    "            f\"- Nunca preencha apenas o m√™s (ex: '01') ou apenas o ano (ex: '2018'). Ambos devem estar presentes. Se o m√™s for desconhecido, use '01' como padr√£o.\\n\"\n",
    "            f\"- O JSON deve come√ßar com '{{ \\\"{section_name}\\\": [' }}'\"\n",
    "        )\n",
    "\n",
    "    elif section_name == \"experiencias\":\n",
    "        prompt_base = (\n",
    "            f\"Voc√™ √© um especialista em RH. Extraia todas as **experi√™ncias profissionais formais** do curr√≠culo abaixo.\\n\\n\"\n",
    "            f\"{schema_snippet}\\n\\n\"\n",
    "            f\"‚ö†Ô∏è **Regras obrigat√≥rias**:\\n\"\n",
    "            f\"- Experi√™ncia √© qualquer atividade em empresa, escola, hospital, √≥rg√£o p√∫blico ou consultoria com *cargo* declarado.\\n\"\n",
    "            f\"- N√ÉO confunda experi√™ncia com forma√ß√£o ou cursos.\\n\"\n",
    "            f\"- Ignore linhas como 'ensino superior', 'p√≥s-gradua√ß√£o', 'MBA', etc., quando n√£o houver cargo.\\n\"\n",
    "            f\"- Para cada experi√™ncia retorne:\\n\"\n",
    "            f\"  ‚Ä¢ **empresa**\\n\"\n",
    "            f\"  ‚Ä¢ **cargo**\\n\"\n",
    "            f\"  ‚Ä¢ **data in√≠cio** e **data fim** devem estar obrigatoriamente no formato **MM/AAAA**, com **m√™s e ano em formato num√©rico** (ex: '03/2022'). Se o m√™s n√£o for informado, use '01' como padr√£o.\\n\"\n",
    "            f\"  ‚Ä¢ **descri√ß√£o** detalhada das atividades\\n\"\n",
    "            f\"- **NUNCA** preencha datas como 'MM/0000', '0000', '2022', 'jan/2020' ou similares. Use sempre n√∫meros.\\n\"\n",
    "            f\"- Se n√£o conseguir extrair ao menos o ANO, marque a experi√™ncia como **inv√°lida** e N√ÉO a inclua.\\n\"\n",
    "            f\"- Cada empresa/cargo deve ser um item separado (n√£o agrupe v√°rias empresas).\\n\"\n",
    "            f\"- Institui√ß√µes educacionais contam como experi√™ncia apenas se houver cargo (ex.: instrutor, professor).\\n\"\n",
    "            f\"- Se n√£o houver experi√™ncias v√°lidas, devolva: {{ \\\"{section_name}\\\": [] }}\\n\"\n",
    "        )\n",
    "        \n",
    "    elif section_name == \"habilidades\":\n",
    "        prompt_base = (\n",
    "            f\"Voc√™ √© um especialista em RH. Extraia as habilidades t√©cnicas e profissionais do curr√≠culo abaixo.\\n\\n\"\n",
    "            f\"Formato: JSON com a chave '{section_name}' e lista de habilidades.\\n\\n\"\n",
    "            f\"{schema_snippet}\\n\\n\"\n",
    "            f\"Regras:\\n\"\n",
    "            f\"- Cada item deve ser uma habilidade √∫nica.\\n\"\n",
    "            f\"- N√£o agrupe v√°rias ferramentas em uma √∫nica string.\\n\"\n",
    "            f\"- Idiomas n√£o entram em habilidades.\"\n",
    "        )\n",
    "    elif section_name == \"idiomas\":\n",
    "        prompt_base = (\n",
    "            f\"Voc√™ √© um especialista em RH. Extraia **apenas os idiomas falados ou estudados** mencionados no curr√≠culo abaixo.\\n\\n\"\n",
    "            f\"Formato esperado:\\n{schema_snippet}\\n\\n\"\n",
    "            f\"‚ö†Ô∏è Regras obrigat√≥rias:\\n\"\n",
    "            f\"- N√ÉO inclua nomes de escolas de idiomas (ex: CNA, Wizard, Fisk, etc.)\\n\"\n",
    "            f\"- N√ÉO deduza idiomas com base em nomes de institui√ß√µes, culturas ou nacionalidade\\n\"\n",
    "            f\"- N√ÉO inclua linguagens de programa√ß√£o (ex: Python, Java, etc.)\\n\"\n",
    "            f\"- Se nenhum idioma for citado claramente, retorne: {{ '{section_name}': [] }}\\n\"\n",
    "            f\"- Campo 'nivel' deve ser: b√°sico, intermedi√°rio, avan√ßado, fluente ou nativo. Use null se ausente.\"\n",
    "        )\n",
    "\n",
    "    chunks = split_chunks(cv_text)\n",
    "    seen_chunks = set()\n",
    "    combined_data = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_key = hash(chunk)\n",
    "        if chunk_key in seen_chunks:\n",
    "            continue\n",
    "        seen_chunks.add(chunk_key)\n",
    "\n",
    "        print(f\"üß© Processando chunk {i+1}/{len(chunks)} com {len(chunk)} caracteres\")\n",
    "        prompt = f\"{prompt_base}\\n\\nCurr√≠culo (parte {i+1}/{len(chunks)}):\\n{chunk}\"\n",
    "\n",
    "        if DEBUG:\n",
    "            print(f\"üì§ Prompt enviado ao modelo:\\n{prompt}\")\n",
    "            if SAVE_LOGS:\n",
    "                salvar_logs(f\"prompt_chunk{i+1}\", prompt)\n",
    "\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                prompt_atual = prompt\n",
    "                output = subprocess.check_output(\n",
    "                    [\"ollama\", \"run\", OLLAMA_MODEL, \"--think=false\"],\n",
    "                    input=prompt_atual.encode(\"utf-8\"),\n",
    "                    stderr=subprocess.STDOUT,\n",
    "                    timeout=300\n",
    "                ).decode(\"utf-8\")\n",
    "\n",
    "                if DEBUG:\n",
    "                    print(f\"üì• Resposta do modelo:\\n{output}\")\n",
    "                    if SAVE_LOGS:\n",
    "                        salvar_logs(f\"resposta_chunk{i+1}\", output)\n",
    "\n",
    "                if \"{\" not in output or \"}\" not in output:\n",
    "                    raise ValueError(\"‚ùå A resposta n√£o cont√©m JSON.\")\n",
    "\n",
    "                raw_json = remove_ansi(output[output.find('{'):output.rfind('}') + 1]).strip()\n",
    "\n",
    "                try:\n",
    "                    parsed = json.loads(raw_json)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"‚ö†Ô∏è Tentando ajuste adaptativo devido a erro de parsing: {e}\")\n",
    "                    prompt_reparo = (\n",
    "                        f\"{prompt_base}\\n\\n\"\n",
    "                        f\"Curr√≠culo (parte {i+1}/{len(chunks)}):\\n{chunk}\\n\\n\"\n",
    "                        f\"‚ö†Ô∏è A resposta anterior gerou o erro:\\n{str(e)}\\n\"\n",
    "                        f\"Por favor, corrija e retorne um JSON v√°lido com a chave '{section_name}'.\"\n",
    "                    )\n",
    "\n",
    "                    if SAVE_LOGS:\n",
    "                        os.makedirs(\"logs\", exist_ok=True)\n",
    "                        clean_output = remove_ansi(output)\n",
    "                        log_data = (\n",
    "                            f\"applicant_id={applicant_id} | Erro de parsing: {str(e)}\\n\"\n",
    "                            f\"Resposta que falhou:\\n{clean_output}\\n\\n\"\n",
    "                        )\n",
    "                        log_filename = os.path.join(\"logs\", f\"reparo_prompt_{datetime.now().date()}.log\")\n",
    "                        with open(log_filename, \"a\", encoding=\"utf-8\") as f:\n",
    "                            f.write(log_data)\n",
    "                        output = subprocess.check_output(\n",
    "                            [\"ollama\", \"run\", OLLAMA_MODEL, \"--think=false\"],\n",
    "                            input=prompt_reparo.encode(\"utf-8\"),\n",
    "                            stderr=subprocess.STDOUT,\n",
    "                            timeout=120\n",
    "                        ).decode(\"utf-8\")\n",
    "\n",
    "                    raw_json = remove_ansi(output[output.find('{'):output.rfind('}') + 1]).strip()\n",
    "                    parsed = json.loads(raw_json)\n",
    "\n",
    "                if isinstance(parsed, list):\n",
    "                    parsed = {section_name: parsed}\n",
    "\n",
    "                if section_name == \"experiencias\":\n",
    "                    for item in parsed.get(\"experiencias\", []):\n",
    "                        if \"data_inicio\" in item:\n",
    "                            item[\"inicio\"] = item.pop(\"data_inicio\")\n",
    "                        if \"data_inicio\" in item:  # seguran√ßa dupla para inconsist√™ncias como \"data inicio\"\n",
    "                            item[\"inicio\"] = item.pop(\"data inicio\")\n",
    "                        if \"data_fim\" in item:\n",
    "                            item[\"fim\"] = item.pop(\"data_fim\")\n",
    "                        if \"data fim\" in item:\n",
    "                            item[\"fim\"] = item.pop(\"data fim\")\n",
    "\n",
    "                combined_data.extend(parsed.get(section_name, []))\n",
    "                break  # Sucesso\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erro ao extrair '{section_name}' do chunk {i+1} (tentativa {attempt}): {e}\")\n",
    "                if attempt == MAX_RETRIES and SAVE_LOGS:\n",
    "                    salvar_logs(f\"erro_chunk{i+1}\", output)\n",
    "\n",
    "    if section_name == \"formacoes\":\n",
    "        combined_data = remover_duplicatas(combined_data, [\"curso\", \"instituicao\", \"ano_inicio\", \"ano_fim\"])\n",
    "    elif section_name == \"experiencias\":\n",
    "        combined_data = remover_duplicatas(combined_data, [\"empresa\", \"cargo\", \"inicio\", \"fim\"])\n",
    "    elif section_name == \"idiomas\":\n",
    "        combined_data = remover_duplicatas(combined_data, [\"idioma\", \"nivel\"])\n",
    "    elif section_name == \"habilidades\":\n",
    "        combined_data = list(set(item.strip() for item in combined_data if isinstance(item, str)))\n",
    "\n",
    "    return {section_name: combined_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97717927-5d05-4c75-aa5c-0e36825d2100",
   "metadata": {},
   "source": [
    "## Chama extra√ß√£o e insere no banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3256ff82-a395-4a2f-b87a-724bc7778e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, result in enumerate(results, 1):\n",
    "    start_time = time.time()\n",
    "    applicant_id = result[\"id\"]\n",
    "    print(f\"\\nüîÑ Processando candidato {idx}/{len(results)} (ID: {applicant_id})\")\n",
    "\n",
    "    cv_text = result[\"cv_pt\"]\n",
    "    if not cv_text or len(cv_text.strip()) < 30:\n",
    "        print(\"‚ö†Ô∏è Curr√≠culo vazio ou muito curto, pulando.\")\n",
    "        continue\n",
    "\n",
    "    schema_form = json.dumps({\"formacoes\": [{\"curso\": \"\", \"nivel\": \"\", \"instituicao\": \"\", \"ano_inicio\": \"\", \"ano_fim\": \"\", \"observacoes\": None}]}, ensure_ascii=False)\n",
    "    schema_exp  = json.dumps({\"experiencias\": [{\"empresa\": \"\", \"cargo\": \"\", \"inicio\": \"\", \"fim\": \"\", \"descricao\": \"\"}]}, ensure_ascii=False)\n",
    "    schema_hab  = json.dumps({\"habilidades\": []}, ensure_ascii=False)\n",
    "    schema_idi  = json.dumps({\"idiomas\": [{\"idioma\": \"\", \"nivel\": \"\"}]}, ensure_ascii=False)\n",
    "\n",
    "    r_form = extract_section(applicant_id, \"formacoes\", schema_form, cv_text)\n",
    "    r_exp  = extract_section(applicant_id, \"experiencias\", schema_exp, cv_text)\n",
    "    r_hab  = extract_section(applicant_id, \"habilidades\", schema_hab, cv_text)\n",
    "    r_idi  = extract_section(applicant_id, \"idiomas\", schema_idi, cv_text)\n",
    "\n",
    "    if not r_form or not r_exp or not r_hab or not r_idi:\n",
    "        print(f\"‚ö†Ô∏è Extra√ß√£o incompleta para candidato {applicant_id}, pulando inser√ß√£o.\")\n",
    "        continue\n",
    "\n",
    "    for idioma in r_idi.get(\"idiomas\", []):\n",
    "        if not isinstance(idioma, dict):\n",
    "            continue\n",
    "        nivel = (idioma.get(\"nivel\") or \"\").strip().lower()\n",
    "        idioma[\"nivel\"] = nivel if nivel in VALID_NIVEIS_IDIOMA else \"\"\n",
    "\n",
    "    r_idi[\"idiomas\"] = [\n",
    "        idioma for idioma in r_idi.get(\"idiomas\", [])\n",
    "        if isinstance(idioma, dict) and idioma_foi_mencionado(cv_text, idioma.get(\"idioma\", \"\"))\n",
    "    ]\n",
    "\n",
    "    for f in r_form.get(\"formacoes\", []):\n",
    "        if \"observacoes\" not in f:\n",
    "            f[\"observacoes\"] = None\n",
    "        if isinstance(f.get(\"ano_fim\"), str) and \"incompleto\" in f[\"ano_fim\"].lower():\n",
    "            f[\"ano_fim\"] = None\n",
    "            f[\"observacoes\"] = \"incompleto\"\n",
    "\n",
    "    final_json = merge_results(r_form, r_exp, r_hab, r_idi)\n",
    "\n",
    "    nivel_maximo_formacao = None\n",
    "    niveis = [\n",
    "        (f.get(\"nivel\") or \"\").strip().lower()\n",
    "        for f in final_json.get(\"formacoes\", [])\n",
    "        if (\n",
    "            (f.get(\"nivel\") or \"\").strip().lower() in ordem_niveis and\n",
    "            not ((f.get(\"observacoes\") or \"\").strip().lower() in {\"trancado\", \"em andamento\", \"interrompida\"})\n",
    "        )\n",
    "    ]\n",
    "    if niveis:\n",
    "        nivel_maximo_formacao = max(niveis, key=lambda x: ordem_niveis[x])\n",
    "\n",
    "    insert_sql = text(\"\"\"\n",
    "        INSERT INTO processed_applicants (\n",
    "            id, data_aceite, nome, cpf, fonte_indicacao, email, email_secundario, data_nascimento,\n",
    "            telefone_celular, telefone_recado, sexo, estado_civil, pcd, endereco, skype, url_linkedin,\n",
    "            facebook, download_cv, cv_pt_json, nivel_maximo_formacao\n",
    "        ) VALUES (\n",
    "            :id, :data_aceite, :nome, :cpf, :fonte_indicacao, :email, :email_secundario, :data_nascimento,\n",
    "            :telefone_celular, :telefone_recado, :sexo, :estado_civil, :pcd, :endereco, :skype, :url_linkedin,\n",
    "            :facebook, :download_cv, :cv_pt_json, :nivel_maximo_formacao\n",
    "        )\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "            data_aceite = EXCLUDED.data_aceite,\n",
    "            nome = EXCLUDED.nome,\n",
    "            cpf = EXCLUDED.cpf,\n",
    "            fonte_indicacao = EXCLUDED.fonte_indicacao,\n",
    "            email = EXCLUDED.email,\n",
    "            email_secundario = EXCLUDED.email_secundario,\n",
    "            data_nascimento = EXCLUDED.data_nascimento,\n",
    "            telefone_celular = EXCLUDED.telefone_celular,\n",
    "            telefone_recado = EXCLUDED.telefone_recado,\n",
    "            sexo = EXCLUDED.sexo,\n",
    "            estado_civil = EXCLUDED.estado_civil,\n",
    "            pcd = EXCLUDED.pcd,\n",
    "            endereco = EXCLUDED.endereco,\n",
    "            skype = EXCLUDED.skype,\n",
    "            url_linkedin = EXCLUDED.url_linkedin,\n",
    "            facebook = EXCLUDED.facebook,\n",
    "            download_cv = EXCLUDED.download_cv,\n",
    "            cv_pt_json = EXCLUDED.cv_pt_json,\n",
    "            nivel_maximo_formacao = EXCLUDED.nivel_maximo_formacao\n",
    "    \"\"\")\n",
    "\n",
    "    print(\"üì¶ JSON final a ser inserido no banco:\")\n",
    "    print(json.dumps(final_json, indent=2, ensure_ascii=False))\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(insert_sql, {\n",
    "            \"id\": applicant_id,\n",
    "            \"data_aceite\": result[\"informacoes_pessoais_data_aceite\"],\n",
    "            \"nome\": result[\"informacoes_pessoais_nome\"],\n",
    "            \"cpf\": result[\"informacoes_pessoais_cpf\"],\n",
    "            \"fonte_indicacao\": result[\"informacoes_pessoais_fonte_indicacao\"],\n",
    "            \"email\": result[\"informacoes_pessoais_email\"],\n",
    "            \"email_secundario\": result[\"informacoes_pessoais_email_secundario\"],\n",
    "            \"data_nascimento\": result[\"informacoes_pessoais_data_nascimento\"],\n",
    "            \"telefone_celular\": result[\"informacoes_pessoais_telefone_celular\"],\n",
    "            \"telefone_recado\": result[\"informacoes_pessoais_telefone_recado\"],\n",
    "            \"sexo\": result[\"informacoes_pessoais_sexo\"],\n",
    "            \"estado_civil\": result[\"informacoes_pessoais_estado_civil\"],\n",
    "            \"pcd\": result[\"informacoes_pessoais_pcd\"],\n",
    "            \"endereco\": result[\"informacoes_pessoais_endereco\"],\n",
    "            \"skype\": result[\"informacoes_pessoais_skype\"],\n",
    "            \"url_linkedin\": result[\"informacoes_pessoais_url_linkedin\"],\n",
    "            \"facebook\": result[\"informacoes_pessoais_facebook\"],\n",
    "            \"download_cv\": result[\"informacoes_pessoais_download_cv\"],\n",
    "            \"cv_pt_json\": json.dumps(final_json, ensure_ascii=False),\n",
    "            \"nivel_maximo_formacao\": nivel_maximo_formacao\n",
    "        })\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"‚úÖ Candidato {applicant_id} inserido com sucesso. ‚è±Ô∏è Tempo: {elapsed:.2f} segundos\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec003a-2d71-4d68-a2a2-e75f9eda3502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

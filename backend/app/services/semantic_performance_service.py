from typing import Dict, List, Any, Optional
import uuid
import json
import os
from datetime import datetime, date
from sqlalchemy.orm import Session
from sqlalchemy import text
import numpy as np
import pandas as pd
from pathlib import Path

from app.core.database import SessionLocal
from app.core.logging import log_info, log_error, log_warning
from app.core.exceptions import APIExceptions


class SemanticPerformanceService:
    """Servi√ßo para an√°lise de performance da busca sem√¢ntica"""
    
    def __init__(self, db: Session = None):
        self.db = db or SessionLocal()
        self.cache_dir = Path("temp_cache")
        self.cache_dir.mkdir(exist_ok=True)
        self.cache_file = self.cache_dir / "semantic_performance_cache.json"
    
    def _is_cache_valid(self) -> bool:
        if not self.cache_file.exists():
            return False
        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
                cache_date = datetime.fromisoformat(cache_data.get('generated_at', ''))
                return cache_date.date() == date.today()
        except Exception as e:
            log_warning(f"Erro ao verificar cache: {e}")
            return False
    
    def _save_cache(self, data: Dict[str, Any]) -> None:
        try:
            cache_data = {
                'generated_at': datetime.now().isoformat(),
                'data': data
            }
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            log_info("Cache de performance sem√¢ntica atualizado")
        except Exception as e:
            log_error(f"Erro ao salvar cache: {e}")
    
    def _load_cache(self) -> Optional[Dict[str, Any]]:
        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
                return cache_data.get('data')
        except Exception as e:
            log_error(f"Erro ao carregar cache: {e}")
            return None
    
    def get_performance_analysis(self) -> Dict[str, Any]:
        if self._is_cache_valid():
            cached_data = self._load_cache()
            if cached_data:
                log_info("Retornando dados do cache de performance")
                return cached_data
        
        log_info("Recalculando dados de performance sem√¢ntica")
        performance_data = self._calculate_performance_metrics()
        self._save_cache(performance_data)
        return performance_data
    
    def _calculate_performance_metrics(self) -> Dict[str, Any]:
        try:
            status_positivos = (
                'Contratado como Hunting',
                'Contratado pela Decision',
                'Documenta√ß√£o PJ',
                'Documenta√ß√£o CLT',
                'Aprovado',
                'Proposta Aceita',
                'Encaminhar Proposta'
            )
            query_vagas = f"""
            SELECT DISTINCT vaga_id
            FROM prospects
            WHERE situacao_candidado IN {status_positivos}
            """
            vagas_result = self.db.execute(text(query_vagas)).fetchall()
            vaga_ids = [row[0] for row in vagas_result]
            if not vaga_ids:
                log_warning("Nenhuma vaga com candidatos aprovados encontrada")
                return self._empty_response()
            log_info(f"Analisando {len(vaga_ids)} vagas com candidatos aprovados")
            resultados = []
            for vaga_id in vaga_ids:
                vagas = self._analyze_vaga_performance(vaga_id, status_positivos)
                resultados.extend(vagas)
                if vagas:
                    log_info(f"Vaga {vaga_id}: {len(vagas)} candidatos aprovados encontrados")
            if not resultados:
                log_warning("Nenhum resultado de an√°lise encontrado")
                return self._empty_response()
            return self._calculate_aggregate_metrics(resultados)
        except Exception as e:
            log_error(f"Erro ao calcular m√©tricas de performance: {str(e)}")
            raise APIExceptions.internal_error("Erro ao calcular m√©tricas de performance")
    
    def _analyze_vaga_performance(self, vaga_id: int, status_positivos: tuple) -> List[Dict]:
        try:
            query_verificacao = """
            SELECT COUNT(*)
            FROM prospects p
            JOIN processed_applicants pa ON pa.id = p.codigo::bigint
            WHERE p.vaga_id = :vaga_id
              AND pa.cv_embedding_vector IS NOT NULL
            """
            qtd_validos = self.db.execute(text(query_verificacao), {"vaga_id": vaga_id}).scalar() or 0
            if qtd_validos < 2:
                return []
            query_candidatos = """
            SELECT pa.id, pa.nome,
                   pa.cv_embedding_vector <=> v.vaga_embedding_vector AS distancia
            FROM processed_applicants pa
            JOIN prospects p ON pa.id = p.codigo::bigint
            JOIN vagas v ON v.id = p.vaga_id
            WHERE v.id = :vaga_id
              AND pa.cv_embedding_vector IS NOT NULL
              AND v.vaga_embedding_vector IS NOT NULL
            ORDER BY distancia ASC
            """
            candidatos = self.db.execute(text(query_candidatos), {"vaga_id": vaga_id}).fetchall()
            if not candidatos:
                return []
            rankeds = [{'id': r[0], 'nome': r[1], 'distancia': float(r[2]), 'rank': i}
                       for i, r in enumerate(candidatos, 1)]
            status_rows = self.db.execute(text("""
                SELECT codigo::bigint AS id, situacao_candidado
                FROM prospects WHERE vaga_id = :vaga_id
            """), {"vaga_id": vaga_id}).fetchall()
            status_map = {r[0]: r[1] for r in status_rows}
            return [
                {'vaga_id': vaga_id, 'candidato_id': c['id'], 'candidato_nome': c['nome'],
                 'rank': c['rank'], 'distancia': c['distancia'], 'status': status_map[c['id']]}
                for c in rankeds if status_map.get(c['id']) in status_positivos
            ]
        except Exception as e:
            log_error(f"Erro ao analisar vaga {vaga_id}: {str(e)}")
            return []
    
    def _calculate_aggregate_metrics(self, resultados: List[Dict]) -> Dict[str, Any]:
        """Calcula m√©tricas agregadas dos resultados"""
        if not resultados:
            return self._empty_response()
        
        df = pd.DataFrame(resultados)
        
        # M√©tricas b√°sicas
        total_aprovados = len(df)
        media_posicao = df['rank'].mean()
        mediana_posicao = df['rank'].median()
        desvio_padrao = df['rank'].std()
        
        # Calcular vagas analisadas corretamente - baseado no notebook
        # qtd_vagas_usadas = df_resultados["vaga_id"].nunique()
        # Conta apenas as vagas que efetivamente geraram resultados (que passaram pelos filtros)
        qtd_vagas_usadas = df['vaga_id'].nunique()
        
        # Distribui√ß√£o por top positions
        top_positions = {}
        for top_n in [1, 3, 5, 10, 20]:
            qtd = (df['rank'] <= top_n).sum()
            pct = (qtd / total_aprovados * 100) if total_aprovados > 0 else 0
            top_positions[f'top_{top_n}'] = {
                'quantidade': int(qtd),
                'percentual': round(float(pct), 1)
            }
        
        # Histograma para gr√°fico
        hist_data = df['rank'].value_counts().sort_index()
        histogram = [
            {'posicao': int(pos), 'quantidade': int(qtd)} 
            for pos, qtd in hist_data.items()
        ]
        
        # Distribui√ß√£o por status
        status_distribution = df['status'].value_counts().to_dict()
        status_data = [
            {'status': status, 'quantidade': int(qtd)}
            for status, qtd in status_distribution.items()
        ]
        
        return {
            "metricas_gerais": {
                "total_aprovados": total_aprovados,
                "media_posicao": round(float(media_posicao), 2),
                "mediana_posicao": float(mediana_posicao),
                "desvio_padrao": round(float(desvio_padrao), 2),
                "vagas_analisadas": qtd_vagas_usadas,  # Baseado no notebook: df_resultados["vaga_id"].nunique()
                "vagas_com_ranking_semantico": qtd_vagas_usadas  # Mesmo valor - vagas que puderam ser ranqueadas semanticamente
            },
            "distribuicao_top_positions": top_positions,
            "histogram_data": histogram,
            "status_distribution": status_data,
            "pgvector_info": {
                "operador_usado": "<=>",
                "tipo_distancia": "Dist√¢ncia de Cosseno",
                "interpretacao": "Menor valor = maior similaridade sem√¢ntica",
                "range_tipico": "0.0 (id√™ntico) a 2.0 (opostos)",
                "ordenacao": "ASC (menores dist√¢ncias primeiro)"
            },
            "mensagem_interpretacao": self._generate_interpretation_message(
                total_aprovados, media_posicao, mediana_posicao, top_positions
            ),
            "interpretacao_estruturada": self._generate_structured_interpretation(
                total_aprovados, media_posicao, mediana_posicao, top_positions
            ),
            "generated_at": datetime.now().isoformat()
        }
    
    def _generate_interpretation_message(self, total: int, media: float, mediana: float, top_pos: Dict) -> str:
        """Gera mensagem de interpreta√ß√£o dos resultados"""
        return f"""## üìä Interpreta√ß√£o dos Resultados

### üìà Vis√£o Geral
- **{total:,} candidatos aprovados** analisados na base de dados
- **Performance da busca sem√¢ntica** para identificar os melhores candidatos

### üéØ M√©tricas de Precis√£o
- **Posi√ß√£o m√©dia dos aprovados:** {media:.1f}¬∫ lugar
- **Metade dos aprovados aparece at√© a {int(mediana)}¬™ posi√ß√£o**
- **{top_pos['top_1']['percentual']:.0f}% dos aprovados** foram os mais recomendados semanticamente
- **{top_pos['top_10']['percentual']:.0f}% dos aprovados** aparecem entre os 10 primeiros

### üîç An√°lise Detalhada
| Top N | Quantidade | Percentual | Interpreta√ß√£o |
|-------|------------|------------|---------------|
| **Top 1** | {top_pos['top_1']['quantidade']} | **{top_pos['top_1']['percentual']}%** | Candidatos que foram a primeira recomenda√ß√£o |
| **Top 3** | {top_pos['top_3']['quantidade']} | **{top_pos['top_3']['percentual']}%** | Candidatos entre os 3 primeiros |
| **Top 5** | {top_pos['top_5']['quantidade']} | **{top_pos['top_5']['percentual']}%** | Candidatos entre os 5 primeiros |
| **Top 10** | {top_pos['top_10']['quantidade']} | **{top_pos['top_10']['percentual']}%** | Candidatos entre os 10 primeiros |

ÔøΩ **Conclus√£o:** A busca sem√¢ntica demonstra {'alta' if media <= 10 else 'moderada' if media <= 20 else 'baixa'} precis√£o, com m√©dia de posi√ß√£o {media:.1f} para candidatos aprovados."""
    
    def _empty_response(self) -> Dict[str, Any]:
        """Retorna resposta vazia quando n√£o h√° dados"""
        return {
            "metricas_gerais": {
                "total_aprovados": 0,
                "media_posicao": 0,
                "mediana_posicao": 0,
                "desvio_padrao": 0,
                "vagas_analisadas": 0,
                "vagas_com_ranking_semantico": 0
            },
            "distribuicao_top_positions": {},
            "histogram_data": [],
            "status_distribution": [],
            "pgvector_info": {
                "operador_usado": "<=>",
                "tipo_distancia": "Dist√¢ncia de Cosseno",
                "interpretacao": "Menor valor = maior similaridade sem√¢ntica",
                "range_tipico": "0.0 (id√™ntico) a 2.0 (opostos)",
                "ordenacao": "ASC (menores dist√¢ncias primeiro)"
            },
            "mensagem_interpretacao": "## üìä Nenhum Dado Dispon√≠vel\n\nN√£o foram encontrados candidatos aprovados para an√°lise.",
            "interpretacao_estruturada": {
                "titulo": "Nenhum Dado Dispon√≠vel",
                "visao_geral": {
                    "total_candidatos": {"valor": 0, "descricao": "candidatos aprovados encontrados"},
                    "objetivo": "An√°lise n√£o p√¥de ser realizada"
                },
                "metricas_precisao": [],
                "analise_detalhada": [],
                "conclusao": {
                    "nivel_precisao": "indefinido",
                    "cor": "gray",
                    "texto": "N√£o foram encontrados dados suficientes para an√°lise.",
                    "recomendacao": "Verifique se existem candidatos aprovados no sistema."
                }
            },
            "generated_at": datetime.now().isoformat()
        }
    
    def clear_cache(self) -> bool:
        """Remove o cache for√ßando rec√°lculo na pr√≥xima chamada"""
        try:
            if self.cache_file.exists():
                self.cache_file.unlink()
                log_info("Cache de performance removido")
                return True
            return False
        except Exception as e:
            log_error(f"Erro ao remover cache: {e}")
            return False
    
    def _generate_structured_interpretation(self, total: int, media: float, mediana: float, top_pos: Dict) -> Dict[str, Any]:
        """Gera interpreta√ß√£o estruturada dos resultados para melhor visualiza√ß√£o no frontend"""
        # Determinar n√≠vel de precis√£o
        if media <= 10:
            nivel_precisao = "alta"
            cor_precisao = "green"
        elif media <= 20:
            nivel_precisao = "moderada"
            cor_precisao = "yellow"
        else:
            nivel_precisao = "baixa"
            cor_precisao = "red"
        
        return {
            "titulo": "Interpreta√ß√£o dos Resultados",
            "visao_geral": {
                "total_candidatos": {
                    "valor": total,
                    "descricao": "candidatos aprovados analisados na base de dados"
                },
                "objetivo": "Performance da busca sem√¢ntica para identificar os melhores candidatos"
            },
            "metricas_precisao": [
                {
                    "label": "Posi√ß√£o m√©dia dos aprovados",
                    "valor": f"{media:.1f}¬∫ lugar",
                    "tipo": "posicao"
                },
                {
                    "label": "Mediana das posi√ß√µes",
                    "valor": f"{int(mediana)}¬™ posi√ß√£o",
                    "descricao": "Metade dos aprovados aparece at√© esta posi√ß√£o"
                },
                {
                    "label": "Top 1 - Primeira recomenda√ß√£o",
                    "valor": f"{top_pos['top_1']['percentual']:.0f}%",
                    "descricao": "dos aprovados foram os mais recomendados semanticamente"
                },
                {
                    "label": "Top 10 - Entre os 10 primeiros",
                    "valor": f"{top_pos['top_10']['percentual']:.0f}%",
                    "descricao": "dos aprovados aparecem entre os 10 primeiros"
                }
            ],
            "analise_detalhada": [
                {
                    "categoria": "Top 1",
                    "quantidade": top_pos['top_1']['quantidade'],
                    "percentual": top_pos['top_1']['percentual'],
                    "interpretacao": "Candidatos que foram a primeira recomenda√ß√£o",
                    "cor": "#10B981"  # green-500
                },
                {
                    "categoria": "Top 3",
                    "quantidade": top_pos['top_3']['quantidade'],
                    "percentual": top_pos['top_3']['percentual'],
                    "interpretacao": "Candidatos entre os 3 primeiros",
                    "cor": "#3B82F6"  # blue-500
                },
                {
                    "categoria": "Top 5",
                    "quantidade": top_pos['top_5']['quantidade'],
                    "percentual": top_pos['top_5']['percentual'],
                    "interpretacao": "Candidatos entre os 5 primeiros",
                    "cor": "#8B5CF6"  # violet-500
                },
                {
                    "categoria": "Top 10",
                    "quantidade": top_pos['top_10']['quantidade'],
                    "percentual": top_pos['top_10']['percentual'],
                    "interpretacao": "Candidatos entre os 10 primeiros",
                    "cor": "#F59E0B"  # amber-500
                }
            ],
            "conclusao": {
                "nivel_precisao": nivel_precisao,
                "cor": cor_precisao,
                "texto": f"A busca sem√¢ntica demonstra {nivel_precisao} precis√£o, com m√©dia de posi√ß√£o {media:.1f} para candidatos aprovados.",
                "recomendacao": self._get_recommendation(nivel_precisao, media)
            }
        }
    
    def _get_recommendation(self, nivel: str, media: float) -> str:
        """Gera recomenda√ß√£o baseada no n√≠vel de precis√£o"""
        if nivel == "alta":
            return "Excelente performance! O algoritmo est√° funcionando muito bem para identificar candidatos qualificados."
        elif nivel == "moderada":
            return "Performance boa, mas h√° espa√ßo para melhorias. Considere ajustar os embeddings ou crit√©rios de matching."
        else:
            return "Performance abaixo do esperado. Recomenda-se revisar o processo de gera√ß√£o de embeddings e os crit√©rios de similaridade."
